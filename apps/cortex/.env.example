# LLM Configuration
# Default to Ollama local instance
LLM_BASE_URL="http://localhost:11434/v1"
LLM_API_KEY="ollama"  # Not used by Ollama, but required by client
LLM_MODEL="llama3"    # Change to your installed model (e.g., mistral, llama3, gemma)
